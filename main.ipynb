{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Instructions\n",
    "\n",
    "### Preparation\n",
    "1. Ensure you have the `requests`, `beautifulsoup4`, and `pandas` libraries installed. If not, install them using `!pip install requests beautifulsoup4 pandas`.\n",
    "2. Enter the desired save file destinations in lines 90, 91\n",
    "3. Run the code in the next cell to define the functions (click on the cell, Shift+Enter)\n",
    "\n",
    "### Usage options\n",
    "\n",
    "##### Syntax:\n",
    "\n",
    "`main(URL(s), phrase(s), want_words=False, want_phrases=False)`\\\n",
    "The funciton is called in the 2nd and 3rd code cells. Run it by clicking on the desired cell and pressing Shift+Enter.\n",
    "\n",
    "##### Arguments:\n",
    "- `URL(s)` (mandatory): A string or list of strings `['url1', 'url2', 'url3']` containing the URL(s) to analyze\n",
    "- `phrase(s)` (optional): A string or list of strings `['phrase1', 'phrase2', 'phrase3']` containing the phrase(s) to count. Default is an empty list.\n",
    "- `want_words` (optional): A boolean `True` or `False` to save word counts to a CSV file. Default is `False`.\n",
    "- `want_phrases` (optional): A boolean `True` or `False` to save phrase counts to a CSV file. Default is `False`.\n",
    "\n",
    "### Notes\n",
    "- The `main` function will print the count of a phrase only if the single phrase is provided as a string.\n",
    "- This script will not accept numbers as phrases, only words.\n"
   ],
   "id": "434a30c20fef90b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T21:00:41.264186Z",
     "start_time": "2024-09-04T21:00:41.245242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def get_word_counts(url):\n",
    "    # Fetch the webpage content\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raise an error for bad status codes\n",
    "\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Get text from the HTML content\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # Split the text into words, excluding punctuation except for apostrophes and excluding numbers\n",
    "    words = re.findall(r\"\\b[a-zA-Z]+(?:'[a-zA-Z]+)?\\b\", text)\n",
    "\n",
    "    # Count the occurrences of each word\n",
    "    word_counts = Counter(words)\n",
    "\n",
    "    # Convert the Counter object to a pandas DataFrame\n",
    "    word_counts_df = pd.DataFrame(word_counts.items(), columns=['Word', 'Count'])\n",
    "    \n",
    "    # Add a column with the URL\n",
    "    word_counts_df.insert(0, 'URL', url)\n",
    "\n",
    "    # Sort the DataFrame by word counts in descending order\n",
    "    word_counts_df = word_counts_df.sort_values(by='Word', ascending=True, key=lambda col: col.str.lower()).reset_index(drop=True)\n",
    "\n",
    "    return word_counts_df\n",
    "\n",
    "def get_phrase_counts(url, phrases):\n",
    "    # Fetch the webpage content\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raise an error for bad status codes\n",
    "\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # Return single count if input is a string\n",
    "    if isinstance(phrases, str):\n",
    "        count = text.count(phrases)\n",
    "        if pd.isna(count): \n",
    "            count = 0\n",
    "        return count\n",
    "    \n",
    "    # Error if input is empty list\n",
    "    if len(phrases) == 0:\n",
    "        phrases_df = pd.DataFrame(columns=['Phrase', 'Count'])\n",
    "        print('No phrase count: Empty list of phrases')\n",
    "        return phrases_df\n",
    "    \n",
    "    # Convert the list of phrases to a DataFrame\n",
    "    phrases_df = pd.DataFrame({'Phrase': phrases})\n",
    "    \n",
    "    # Count the occurrences of each phrase\n",
    "    phrase_counts = []\n",
    "    for phrase in phrases_df['Phrase']:\n",
    "        count = text.count(phrase)\n",
    "        phrase_counts.append(count)\n",
    "\n",
    "    # Update the DataFrame with the counts\n",
    "    phrases_df['Count'] = phrase_counts\n",
    "    phrases_df['Count'] = phrases_df['Count'].fillna(0).astype(int)\n",
    "    \n",
    "    # Add a column with the URL\n",
    "    phrases_df.insert(0, 'URL', url)\n",
    "    \n",
    "    # Sort the DataFrame by phrase counts in alphabetical order\n",
    "    phrases_df = phrases_df.sort_values(by=\"Phrase\", ascending=True, key=lambda col: col.str.lower()).reset_index(drop=True)\n",
    "\n",
    "    return phrases_df\n",
    "\n",
    "def save_dataframes_to_csv(url, word_counts_df, phrases_df, want_words=False, want_phrases=False):\n",
    "    \n",
    "    # Get the current date and time\n",
    "    now = datetime.now()\n",
    "\n",
    "    # Format the date and time to YYYYMMDDHHMMSS\n",
    "    timestamp = now.strftime('%Y%m%d%H%M%S')\n",
    "    \n",
    "    # Generate file names based on the URL\n",
    "    base_name = re.sub(r'\\W+', '_', url)\n",
    "    word_counts_file = os.path.expanduser(f'~/Downloads/{base_name}_word_counts_{timestamp}.csv')\n",
    "    phrases_file = os.path.expanduser(f'~/Downloads/{base_name}_phrases_{timestamp}.csv')\n",
    "\n",
    "    # Save the DataFrames as CSV files\n",
    "    if want_words:\n",
    "        word_counts_df.to_csv(word_counts_file, index=False)\n",
    "        print(f'{url} word counts saved to: {word_counts_file}')\n",
    "    if want_phrases:\n",
    "        phrases_df.to_csv(phrases_file, index=False)\n",
    "        print(f'{url} phrase counts saved to: {phrases_file}')\n",
    "    \n",
    "    return\n",
    "\n",
    "# Main function to run the program\n",
    "def single_url(url, phrases_list=[], want_words=False, want_phrases=False):\n",
    "    \n",
    "    # Check if the input is a single phrase, print count\n",
    "    if isinstance(phrases_list, str):\n",
    "        try:\n",
    "            count = get_phrase_counts(url, phrases_list)\n",
    "            print(f'{url} count of \"{phrases_list}\": {count}')\n",
    "        except:\n",
    "            print(f'Error getting phrase count for {phrases_list}')\n",
    "        \n",
    "        # Save string to a list\n",
    "        phrases_list = [phrases_list]\n",
    "\n",
    "    # Try getting phrase counts\n",
    "    try:\n",
    "        phrases_df = get_phrase_counts(url, phrases_list)\n",
    "    except:\n",
    "        print(f'Error getting phrase counts for {url}')\n",
    "    \n",
    "    # Try getting word counts\n",
    "    try:\n",
    "        word_counts_df = get_word_counts(url)\n",
    "    except:\n",
    "        print(f'Error getting word counts for {url}')\n",
    "\n",
    "    # Save the DataFrames to CSV files\n",
    "    save_dataframes_to_csv(url, word_counts_df, phrases_df, want_words, want_phrases)\n",
    "    \n",
    "    return\n",
    "    \n",
    "def main(urls, phrases_list=[], want_words=False, want_phrases=False):\n",
    "    \n",
    "    # Check if input is a list of URLs\n",
    "    if isinstance(urls, list):\n",
    "        errors = []\n",
    "        # Loop through the list of URLs\n",
    "        for url in urls:\n",
    "            try:\n",
    "                single_url(url, phrases_list, want_words, want_phrases)\n",
    "            except:\n",
    "                print(f'Error processing URL: {url}')\n",
    "                errors.append(url)\n",
    "        if len(errors) == 0:\n",
    "            print('All URLs processed successfully')\n",
    "        else:\n",
    "            print(f'Error URLs:\\n')\n",
    "            print(errors, sep='\\n')\n",
    "            print(f'Error processing {len(errors)} URLs. All other URLs processed successfully')\n",
    "    \n",
    "    # If input is a single URL, run the single_url function\n",
    "    elif isinstance(urls, str):\n",
    "        try:\n",
    "            single_url(urls, phrases_list, want_words, want_phrases)\n",
    "            print('URL processed successfully')\n",
    "        except: \n",
    "            print('Error processing URL')\n",
    "    \n",
    "    # Error if input is not a list or string\n",
    "    else:\n",
    "        print('Error: Invalid URL input')\n",
    "    \n",
    "    return\n",
    "    "
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T20:29:22.491312Z",
     "start_time": "2024-09-04T20:29:22.488053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Enter URLs here\n",
    "urls = [\n",
    "    'https://developer.atlassian.com/cloud/confluence/getting-started-with-connect/',\n",
    "    'https://developer.atlassian.com/cloud/confluence/storing-data-with-entity-properties/',\n",
    "    'https://developer.atlassian.com/cloud/confluence/connect-frameworks-and-tools/'\n",
    "]\n",
    "\n",
    "# Enter phrases here\n",
    "phrases = [\n",
    "    'complete this tutorial',\n",
    "    'Atlassian Connect',\n",
    "    'Confluence Cloud',\n",
    "    'Connect framework',\n",
    "    'cloud development site'\n",
    "]"
   ],
   "id": "26a19568b0764545",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T21:04:52.272682Z",
     "start_time": "2024-09-04T21:04:45.838135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function that takes above URLs, phrases and saves word and phrase counts to CSV files\n",
    "main(urls, phrases, want_words=True, want_phrases=True)"
   ],
   "id": "4dabe3e912f03427",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://developer.atlassian.com/cloud/confluence/getting-started-with-connect/ count of \"is\": 35\n",
      "https://developer.atlassian.com/cloud/confluence/storing-data-with-entity-properties/ count of \"is\": 12\n",
      "https://developer.atlassian.com/cloud/confluence/connect-frameworks-and-tools/ count of \"is\": 8\n",
      "All URLs processed successfully\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T21:06:15.530314Z",
     "start_time": "2024-09-04T21:06:14.132397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function that takes a single URL and phrase, only prints the count\n",
    "main('https://en.wikipedia.org/wiki/SAP', 'SAP')"
   ],
   "id": "53d4f7be98703c8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/SAP count of \"SAP\": 334\n",
      "URL processed successfully\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ce4d2d365d144369"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
